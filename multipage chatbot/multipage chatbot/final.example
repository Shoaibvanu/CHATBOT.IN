import streamlit as st
from dotenv import load_dotenv
import openai
from htmlTemplates import css, bot_template, user_template

from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import HuggingFaceInstructEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain

import fitz
import io

load_dotenv()

# Set OpenAI API key
openai.api_key = "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"

def is_legal_response(response):
    legal_keywords = ["indian law", "legal", "law", "section", "subsection"]
    return any(keyword in response.lower() for keyword in legal_keywords)

def get_openai_response(question, model="gpt-3.5-turbo"):
    messages = [
        {"role": "system", "content": "You are a helpful legal assistant specialized in Indian law."},
        {"role": "user", "content": f"Legal question: {question}"}
    ]

    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        max_tokens=1000
    )

    if is_legal_response(response['choices'][0]['message']['content']):
        return response['choices'][0]['message']['content'].strip()
    else:
        return "I don't know the answer to that question about Indian law."

def get_pdf_text(pdf_docs):
    text = ""
    for pdf_file in pdf_docs:
        # Read the content of the BytesIO object
        pdf_content = io.BytesIO(pdf_file.read())

        # Create a document object
        doc = fitz.open(stream=pdf_content, filetype="pdf")

        for page_num in range(doc.page_count):
            # Get the page by index
            page = doc.load_page(page_num)

            # Read a Page
            text += page.get_text()

        doc.close()

    return text

def get_text_chunks(text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=2000,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(text)
    return chunks

def get_vectorstore(text_chunks):
    embeddings = HuggingFaceInstructEmbeddings(model_name="nlpaueb/legal-bert-base-uncased")
    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)
    return vectorstore

def get_conversation_chain(vectorstore):
    llm = ChatOpenAI(temperature=0.4, max_tokens=2000)
    memory = ConversationBufferMemory(
        memory_key='chat_history', return_messages=True)
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(),
        memory=memory
    )
    return conversation_chain

def handle_userinput(user_question, pdf_docs, conversation_chain):
    if "access to the pdf" in user_question.lower():
        response = "Yes, I have access to the provided PDFs. Please let me know if you have any specific questions or if there's anything specific you would like assistance with regarding the content of the PDFs."
    else:
        # Use OpenAI response
        openai_response = get_openai_response(user_question)

        # Process PDFs and incorporate information into the response
        pdf_text = get_pdf_text(pdf_docs)
        pdf_chunks = get_text_chunks(pdf_text)
        pdf_vectorstore = get_vectorstore(pdf_chunks)
        conversation_chain.retriever.vectorstore = pdf_vectorstore

        # Get response from the conversation chain
        chain_response = conversation_chain.get_response(user_question)

        # Combine OpenAI and PDF-based responses
        response = f"{openai_response}\n\nBased on the provided PDFs: {chain_response}"

    st.write(bot_template.replace("{{MSG}}", response), unsafe_allow_html=True)

def main():
    st.set_page_config(page_title="Legal and Document Chatbot", page_icon="icon.png")
    st.write(css, unsafe_allow_html=True)
    
    st.header("HOW MAY I ASSIST YOU")
    
    user_question = st.text_input("ASK A LEGAL QUESTION RELATED TO INDIAN LAW")
    pdf_docs = None
    
    with st.sidebar:
        st.subheader("Your documents")
        pdf_docs = st.file_uploader(
            "Upload your PDFs here and click on 'Process'", accept_multiple_files=True)
        if st.button("Process"):
            with st.spinner("Processing"):
                # get pdf text
                raw_text = get_pdf_text(pdf_docs)

                # get the text chunks
                text_chunks = get_text_chunks(raw_text)

                # create vector store
                vectorstore = get_vectorstore(text_chunks)

                # create conversation chain
                conversation_chain = get_conversation_chain(vectorstore)

    if user_question and pdf_docs:
        handle_userinput(user_question, pdf_docs, conversation_chain)

if __name__ == '__main__':
    main()
